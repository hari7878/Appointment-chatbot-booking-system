# This is an example configuration file.
# Copy this to a new file named .env and fill in your actual values.

# --- LLM Configuration ---
LLM_PROVIDER="deepseek"

# --- API Keys (only fill what you use) ---
DEEPSEEK_API_KEY="ollama" # Placeholder for local models
QWEN_API_KEY=""
OPENAI_API_KEY=""
GOOGLE_API_KEY=""
ANTHROPIC_API_KEY=""

# --- Model Endpoints & Names ---
OLLAMA_BASE_URL="http://localhost:11434"
OLLAMA_MODEL="llama3"

DEEPSEEK_BASE_URL="http://localhost:11434/v1"
DEEPSEEK_MODEL="deepseek-coder:6.7b"

QWEN_BASE_URL="http://localhost:11434/v1"
QWEN_MODEL="qwen:7b"
